name: test-linux

on:
  pull_request:
  push:
    branches:
      - master
      - canary
      - v[0-9]+.x-staging
      - v[0-9]+.x

env:
  PYTHON_VERSION: 3.9
  FLAKY_TESTS: dontcare

jobs:
  test-linux:
    runs-on: ${{ matrix.runner_type }}
    continue-on-error: true
    strategy:
      matrix:
        runner_type: [ds2v2,ds2v3,ds3v2,ds4v2,ds5v2,f2s,f4s,f32s,f64s,d2asv4,d2dsv4,m5dlarge,m5large]
    env:
      #### For stat collection
      runId: ${{ matrix.runner_type }}-${{ github.workflow }}
      artifactsDir: artifacts/${{ github.repository }}
      iostatFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-iostat.txt
      vmstatFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-vmstat.txt
      timingFile: artifacts/${{ github.repository }}/${{ matrix.runner_type }}-timing.txt
      ##########################
    
    steps:
      #### Start stat collection
      - run: |
          sudo apt-get update
          sudo apt-get install build-essential
          sudo apt install make
      - run: mkdir -p ${{ runner.temp }}/${{ env.artifactsDir }}
      - run: iostat -yxmt 1 > ${{ runner.temp }}/${{ env.iostatFile }} &
      - run: vmstat -n 1 > ${{ runner.temp }}/${{ env.vmstatFile }} &
      - run: date -R > ${{ runner.temp }}/${{ env.timingFile }}
      ##########################
      - uses: actions/checkout@v2
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: actions/setup-node@v1
      - name: Environment Information
        run: npx envinfo
      - name: Build
        run: make build-ci -j2 V=1 CONFIG_FLAGS="--error-on-warn"
      #- name: Test
      #  run: make run-ci -j2 V=1 TEST_CI_ARGS="-p actions"
     #### Collect/upload stats
      - run: date -R >> ${{ runner.temp }}/${{ env.timingFile }}
      - name: Upload a Build Artifact
        uses: actions/upload-artifact@v2
        with:
          name: perfdata
          path: ${{ runner.temp }}/${{ env.artifactsDir }}
          if-no-files-found: error
      - name: Runner workspace path
        run: |
          echo "Cleaning up previous run"
          rm -rf "${{ github.workspace }}"
      ##########################

  process:
    name: Process Perf Data
    continue-on-error: true
    runs-on: ubuntu-latest
    needs: [test-linux]
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: 3.x
          architecture: x64
      - uses: actions/checkout@v2
        with:
          repository: pjquirk/runnerperf
          path: runnerperf
      - uses: actions/checkout@v2
        with:
          repository: pjquirk/iostat-tool
          path: runnerperf/iostat-tool
      - name: Download a Build Artifact
        uses: actions/download-artifact@v2  
        with:
          name: perfdata
          path: runnerperf/data
      - name: Prereqs
        run: sudo apt -y install datamash  
      - name: Process stats
        run: |
          cd runnerperf
          (cd iostat-tool && python setup.py develop)
          ls -l data
          script/dumpcsv.sh data output
          script/aggregate.sh output ${{ github.repository }}
      - name: Upload a Build Artifact
        uses: actions/upload-artifact@v2
        with:
          name: summary-perfdata
          path: runnerperf/output/summary.csv
          if-no-files-found: error
